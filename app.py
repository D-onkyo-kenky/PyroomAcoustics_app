import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import pyroomacoustics as pra
import io
from scipy.io import wavfile
from scipy.io.wavfile import write
import os
from acoustic_utils import octave_band_filter, reverb_time_T30, cut_signal_by_threshold

font_path = "fonts/static/NotoSansJP-Light.ttf"
font_prop = fm.FontProperties(fname=font_path)

st.set_page_config(page_title="éŸ³éŸ¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸ”Š éŸ³éŸ¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ—ãƒª")

# --- ææ–™ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
csv_path = "materials.csv"
if os.path.exists(csv_path):
    materials_df = pd.read_csv(csv_path)
else:
    st.error("materials.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç·¨é›†ãƒšãƒ¼ã‚¸ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- éƒ¨å±‹ã®è¨­å®š ---
st.sidebar.header("éƒ¨å±‹ã®è¨­å®š")
room_width = st.sidebar.number_input("éƒ¨å±‹ã®å¹… X  [m]", 1.0, 100.0, 8.0)
room_depth = st.sidebar.number_input("éƒ¨å±‹ã®å¥¥è¡Œ Y  [m]", 1.0, 100.0, 10.0)
room_height = st.sidebar.number_input("éƒ¨å±‹ã®é«˜ã• Z  [m]", 1.0, 20.0, 3.0)
room_dim = [room_width, room_depth, room_height]

# --- éŸ³æºã¨ãƒã‚¤ã‚¯ã®ä½ç½® ---
st.sidebar.header("éŸ³æºã®ä½ç½®")
src_x = st.sidebar.slider("ğŸ”‰éŸ³æº X [m]", 0.0, room_width, room_width / 2)
src_y = st.sidebar.slider("ğŸ”‰éŸ³æº Y [m]", 0.0, room_depth, room_depth / 2)
src_z = st.sidebar.slider("ğŸ”‰éŸ³æº Z [m]", 0.0, room_height, 1.2)
st.sidebar.header("ãƒã‚¤ã‚¯ã®ä½ç½®")
mic_x = st.sidebar.slider("ğŸ™ãƒã‚¤ã‚¯ X [m]", 0.0, room_width, room_width * 0.85)
mic_y = st.sidebar.slider("ğŸ™ãƒã‚¤ã‚¯ Y [m]", 0.0, room_depth, room_depth * 0.85)
mic_z = st.sidebar.slider("ğŸ™ãƒã‚¤ã‚¯ Z [m]", 0.0, room_height, 1.2)

# --- éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ ---
st.sidebar.header("éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«")
audio_file = st.sidebar.file_uploader("WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['wav'])
if audio_file is not None:
    fs, audio = wavfile.read(audio_file)
    if audio.ndim > 1:
        audio = np.mean(audio, axis=1)
    audio = audio.astype(np.float32) / np.max(np.abs(audio))
elif os.path.exists("source.wav"):
    fs, audio = wavfile.read("source.wav")
    if audio.ndim > 1:
        audio = np.mean(audio, axis=1)
    audio = audio.astype(np.float32) / np.max(np.abs(audio))
    st.sidebar.info("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®éŸ³æºã‚’ä½¿ç”¨ä¸­")
else:
    st.sidebar.error("éŸ³æºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.stop()

# --- éŸ³ç·šæ³•ãƒ»è™šåƒæ³•ã®è¨­å®š ---
st.sidebar.header("è©³ç´°è¨­å®š")
array_numbers = st.sidebar.number_input("éŸ³ç·šæ•°", min_value=10000, max_value=1000000, value=20000, step=10000)
radius = st.sidebar.number_input("å—éŸ³åŠå¾„[m]", 0.1, 1.0, 0.5)
energy_threshold = st.sidebar.number_input("ã‚¨ãƒãƒ«ã‚®ãƒ¼é–¾å€¤", min_value=1e-7, max_value=1e-1, value=1e-5, step=1e-7, format="%.2e")
image_numbers= st.sidebar.number_input("è™šåƒæ³•ã®åå°„å›æ•°", 0, 100, 3)


# --- å„é¢ã®ææ–™é¸æŠ ---
st.subheader("ææ–™æŒ‡å®šï¼ˆå„é¢ï¼‰")

# ææ–™åãƒªã‚¹ãƒˆ
material_names = materials_df['material'].tolist()
wall_colors = {
    'west': 'red', 'east': 'blue', 'south': 'green',
    'north': 'orange', 'floor': 'gray', 'ceiling': 'purple'
}

# ãƒ—ãƒªã‚»ãƒƒãƒˆå®šç¾©
presets = {
    "ãƒ–ãƒ©ã‚¤ãƒ³ãƒ‰å¸éŸ³ãªã—": {
        'west': 'low abs board',
        'east': 'glass',
        'south': 'glass',
        'north': 'low abs board',
        'floor': 'low abs board',
        'ceiling': 'low abs board'
    },
    "ãƒ–ãƒ©ã‚¤ãƒ³ãƒ‰å¸éŸ³ã‚ã‚Š": {
        'west': 'low abs board',
        'east': 'â˜…abs_blind',
        'south': 'â˜…abs_blind',
        'north': 'low abs board',
        'floor': 'low abs board',
        'ceiling': 'low abs board'
    },
    "ã‚³ãƒ³ã‚¯ãƒªãƒ¼ãƒˆ": {
        'west': 'concrete',
        'east': 'concrete',
        'south': 'concrete',
        'north': 'concrete',
        'floor': 'concrete',
        'ceiling': 'concrete'
    }    
}

# UIã§é¸ã¶ãƒ—ãƒªã‚»ãƒƒãƒˆå
selected_preset_name = st.selectbox("ğŸ› ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é¸æŠ", list(presets.keys()))

# ãƒ—ãƒªã‚»ãƒƒãƒˆé©ç”¨ãƒ•ãƒ©ã‚°
if "apply_preset" not in st.session_state:
    st.session_state.apply_preset = False

# é©ç”¨ãƒœã‚¿ãƒ³
if st.button("ğŸ“‹ ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é©ç”¨"):
    st.session_state.apply_preset = True
    st.session_state.preset_values = presets[selected_preset_name]

# ã‚»ãƒ¬ã‚¯ã‚¿ç”Ÿæˆ
cols = st.columns(6)
walls = {}

for i, wall in enumerate(wall_colors):
    with cols[i]:
        # ãƒ—ãƒªã‚»ãƒƒãƒˆé©ç”¨æ™‚
        if st.session_state.apply_preset:
            default_material = st.session_state.preset_values[wall]
        else:
            default_material = st.session_state.get(f"{wall}_material", material_names[0])

        selected = st.selectbox(
            f"{wall}ï¼ˆ{wall_colors[wall]}ï¼‰",
            material_names,
            index=material_names.index(default_material),
            key=f"{wall}_material"
        )
        walls[wall] = selected

# ä¸€åº¦é©ç”¨ã—ãŸã‚‰æ¬¡å›ä»¥é™ã¯é©ç”¨ãƒ•ãƒ©ã‚°ã‚’ã‚ªãƒ•ã«ã™ã‚‹
st.session_state.apply_preset = False


# --- å¹³é¢å›³æç”» ---
dpi = 100
fig = plt.figure(figsize=(300 / dpi, 300 / dpi), dpi=dpi)
ax = fig.add_subplot(111)
ax.plot([0, 0], [0, room_depth], color='red', linewidth=3, label='west')
ax.plot([room_width, room_width], [0, room_depth], color='blue', linewidth=3, label='east')
ax.plot([0, room_width], [0, 0], color='green', linewidth=3, label='south')
ax.plot([0, room_width], [room_depth, room_depth], color='orange', linewidth=3, label='north')
ax.plot(src_x, src_y, '^', label='éŸ³æº')
ax.plot(mic_x, mic_y, '*', label='ãƒã‚¤ã‚¯')
ax.set_xlim(-1, room_width + 1)
ax.set_ylim(-1, room_depth + 1)
ax.set_aspect('equal')
ax.set_title("éƒ¨å±‹ã®å¹³é¢å›³ï¼ˆä¸Šã‹ã‚‰è¦‹ãŸå›³ï¼‰", fontproperties=font_prop, fontsize=12)
ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), prop=font_prop)
st.pyplot(fig,use_container_width=False)

# --- ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ ---
if st.button("â–¶ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"):
    # ææ–™å®šç¾©
    material_dict = {
        row['material']: pra.Material({
            'coeffs': [row[f'{f}Hz'] for f in [125, 250, 500, 1000, 2000, 4000]],
            'center_freqs': [125, 250, 500, 1000, 2000, 4000]
        }, scattering=row['scattering']) for _, row in materials_df.iterrows()
    }

    # éƒ¨å±‹ã®ä½œæˆ
    room = pra.ShoeBox(
        room_dim,
        fs=fs,
        materials={face: material_dict[walls[face]] for face in walls},
        max_order=image_numbers, # è™šåƒæ³•ã®åå°„å›æ•°
        ray_tracing=True, # éŸ³ç·šæ³•ã®è¨­å®š
        air_absorption=True # ç©ºæ°—æ¸›è¡°ã‚ã‚Š
    )

    # éŸ³ç·šæ³•ã®è¨­å®š
    room.set_ray_tracing(
    receiver_radius=radius,     # å—éŸ³åŠå¾„[m]ï¼ˆä¸€èˆ¬çš„ã«ã¯0.1ã€œ0.5ï¼‰
    n_rays=array_numbers,       # ç™ºå°„ã™ã‚‹éŸ³ç·šã®æ•°ï¼ˆç²¾åº¦ã¨é€Ÿåº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ï¼‰
    energy_thres=energy_threshold      # ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®é–¾å€¤ï¼ˆä¾‹ï¼šå…ƒã®ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®1/1e-6ã¾ã§è¿½è·¡ã™ã‚‹ï¼‰
    )

    room.add_source([src_x, src_y, src_z], signal=audio)
    room.add_microphone_array(pra.MicrophoneArray([[mic_x], [mic_y], [mic_z]], fs))
    room.compute_rir()
    room.simulate()

    # å†ç”Ÿã¨å¯è¦–åŒ–
    audio_clipped = np.clip(audio, -1.0, 1.0)
    audio_int16 = (audio_clipped * 32767).astype(np.int16)
    audio_bytes = io.BytesIO()
    write(audio_bytes, fs, audio_int16)
    audio_bytes.seek(0)
    st.subheader("ğŸ”‰ å…ƒã®éŸ³æº")
    st.audio(audio_bytes, format="audio/wav")

    # ç•³ã¿è¾¼ã¿
    signal = room.mic_array.signals[0] # ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”ã®ç•³ã¿è¾¼ã¿ï¼‹è·é›¢æ¸›è¡°ã‚’é©ç”¨
    #signal = cut_signal_by_threshold(signal, -80) # éŸ³æºã®é•·ã•ã‚’èª¿æ•´ï¼ˆæœ€å¾Œã‚‰ã¸ã‚“ã®æ®‹éŸ¿ã‚’ã‚«ãƒƒãƒˆï¼‰

    # éŸ³åœ§ã‚¹ã‚±ãƒ¼ãƒ«ã®ã¾ã¾å†ç”Ÿï¼ˆè‡ªå‹•æ­£è¦åŒ–ã‚’é¿ã‘ã‚‹ï¼‰
    signal_clipped = np.clip(signal, -1.0, 1.0)  # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã§å®‰å…¨å‡¦ç†
    signal_int16 = (signal_clipped * 32767).astype(np.int16)
    wav_bytes = io.BytesIO()
    write(wav_bytes, fs, signal_int16)
    wav_bytes.seek(0)

    # ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”ã®ç•³ã¿è¾¼ã¿
    st.subheader("ğŸ§ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³æº")
    signal_norm = signal / (np.max(np.abs(signal)) + 1e-12)
    signal_int16_norm = (signal_norm * 32767).astype(np.int16)
    wav_bytes_norm = io.BytesIO()
    write(wav_bytes_norm, fs, signal_int16_norm)
    wav_bytes_norm.seek(0)
    st.audio(wav_bytes_norm, format="audio/wav")

    # ã“ã¡ã‚‰ã¯æŠ˜ã‚ŠãŸãŸã¿è¡¨ç¤ºã«ã™ã‚‹ã€Œå®Ÿéš›ã®è·é›¢ãƒ»å¸éŸ³ã®å½±éŸ¿ã‚’ãã®ã¾ã¾åæ˜ ã—ãŸéŸ³ã€
    with st.expander("ğŸ§ è·é›¢æ„Ÿã‚’åæ˜ ã—ãŸéŸ³ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹ï¼‰"):
        st.caption("è·é›¢æ„Ÿã‚’åæ˜ ã—ãŸéŸ³")
        signal_clipped = np.clip(signal, -1.0, 1.0)
        signal_int16 = (signal_clipped * 32767).astype(np.int16)
        wav_bytes = io.BytesIO()
        write(wav_bytes, fs, signal_int16)
        wav_bytes.seek(0)
        st.audio(wav_bytes, format="audio/wav")


    # ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”ã®å–å¾—ã¨æ­£è¦åŒ–
    rir = room.rir[0][0]
    rir_norm = rir / (np.max(np.abs(rir)) + 1e-12) # æ­£è¦åŒ–

    # æ®‹éŸ¿æ™‚é–“ï¼ˆT30ï¼‰
    st.subheader("â± æ®‹éŸ¿æ™‚é–“")
    cfreqs = [63, 125, 250, 500, 1000, 2000, 4000]
    T30_values = []
    for fc in cfreqs:
        y = octave_band_filter(rir_norm, fs, fc)
        T30 = reverb_time_T30(y, fs)
        T30_values.append(round(T30, 1)) # å°æ•°ç‚¹ç¬¬ä¸€
    df = pd.DataFrame({'ä¸­å¿ƒå‘¨æ³¢æ•° (Hz)': cfreqs, 'T30 (s)': T30_values})
    st.dataframe(df, width=300, hide_index=True)

    # ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”ã®ã‚°ãƒ©ãƒ•ã¨å†ç”Ÿï¼ˆæ­£è¦åŒ–ã—ãªã„ï¼‰
    with st.expander("ğŸ“ˆ ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹ï¼‰"):
        fig, ax = plt.subplots(figsize=(8, 3))
        ax.plot(np.arange(len(rir)) / fs, rir)
        ax.set_xlabel("Time [s]", fontproperties=font_prop)
        ax.set_ylabel("Amplitude", fontproperties=font_prop)
        ax.set_title("ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”", fontproperties=font_prop)
        st.pyplot(fig, use_container_width=False)

        col1, col2 = st.columns(2)
        with col1:
            st.caption("å®Ÿéš›ã®è·é›¢ãƒ»å¸éŸ³ã®å½±éŸ¿ã‚’ãã®ã¾ã¾åæ˜ ã—ãŸéŸ³")
            rir_clipped = np.clip(rir, -1.0, 1.0)
            rir_int16 = (rir_clipped * 32767).astype(np.int16)
            rir_bytes = io.BytesIO()
            write(rir_bytes, fs, rir_int16)
            rir_bytes.seek(0)
            st.audio(rir_bytes, format="audio/wav")

        with col2:
            st.caption("éŸ³é‡ã‚’èãã‚„ã™ãè‡ªå‹•èª¿æ•´ã—ãŸéŸ³")
            rir_norm = rir / (np.max(np.abs(rir)) + 1e-12)
            rir_int16_norm = (rir_norm * 32767).astype(np.int16)
            rir_bytes_norm = io.BytesIO()
            write(rir_bytes_norm, fs, rir_int16_norm)
            rir_bytes_norm.seek(0)
            st.audio(rir_bytes_norm, format="audio/wav")