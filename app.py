import streamlit as st
import numpy as np
import pandas as pd
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import pyroomacoustics as pra
from scipy.io import wavfile
import os
from acoustic_utils import octave_band_filter, reverb_time_T30

font_path = "fonts/static/NotoSansJP-Light.ttf"
font_prop = fm.FontProperties(fname=font_path)

st.set_page_config(page_title="éŸ³éŸ¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸ”Š éŸ³éŸ¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¢ãƒ—ãƒª")

# --- ææ–™ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
csv_path = "materials.csv"
if os.path.exists(csv_path):
    materials_df = pd.read_csv(csv_path)
else:
    st.error("materials.csv ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç·¨é›†ãƒšãƒ¼ã‚¸ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- éƒ¨å±‹ã®è¨­å®š ---
st.sidebar.header("éƒ¨å±‹ã®è¨­å®š")
room_width = st.sidebar.number_input("éƒ¨å±‹ã®å¹… [m]", 1.0, 50.0, 8.0)
room_depth = st.sidebar.number_input("éƒ¨å±‹ã®å¥¥è¡Œ [m]", 1.0, 50.0, 10.0)
room_height = st.sidebar.number_input("éƒ¨å±‹ã®é«˜ã• [m]", 1.0, 10.0, 3.0)
room_dim = [room_width, room_depth, room_height]

# --- éŸ³æºã¨ãƒã‚¤ã‚¯ã®ä½ç½® ---
st.sidebar.header("éŸ³æºã¨ãƒã‚¤ã‚¯ã®ä½ç½®")
src_x = st.sidebar.slider("éŸ³æº X [m]", 0.0, room_width, room_width / 10)
src_y = st.sidebar.slider("éŸ³æº Y [m]", 0.0, room_depth, room_depth / 10)
src_z = st.sidebar.slider("éŸ³æº Z [m]", 0.0, room_height, 1.2)
mic_x = st.sidebar.slider("ãƒã‚¤ã‚¯ X [m]", 0.0, room_width, room_width * 0.75)
mic_y = st.sidebar.slider("ãƒã‚¤ã‚¯ Y [m]", 0.0, room_depth, room_depth * 0.6)
mic_z = st.sidebar.slider("ãƒã‚¤ã‚¯ Z [m]", 0.0, room_height, 1.2)

# --- å„é¢ã®ææ–™é¸æŠ ---
st.subheader("éƒ¨å±‹ã®å¹³é¢å›³ã¨å£ææŒ‡å®š")
material_names = materials_df['material'].tolist()
wall_colors = {
    'west': 'red', 'east': 'blue', 'south': 'green',
    'north': 'orange', 'floor': 'gray', 'ceiling': 'purple'
}
walls = {}
cols = st.columns(6)
for i, wall in enumerate(wall_colors):
    with cols[i]:
        walls[wall] = st.selectbox(f"{wall} ({wall_colors[wall]})", material_names, key=wall)

# --- å¹³é¢å›³æç”» ---
dpi = 100
fig = plt.figure(figsize=(600 / dpi, 300 / dpi), dpi=dpi)
ax = fig.add_subplot(111)
ax.plot([0, room_width], [0, 0], color='green', linewidth=3, label='south')
ax.plot([0, room_width], [room_depth, room_depth], color='orange', linewidth=3, label='north')
ax.plot([0, 0], [0, room_depth], color='red', linewidth=3, label='west')
ax.plot([room_width, room_width], [0, room_depth], color='blue', linewidth=3, label='east')
ax.plot(src_x, src_y, 'ko', label='éŸ³æº')
ax.plot(mic_x, mic_y, 'ks', label='ãƒã‚¤ã‚¯')
ax.set_xlim(-1, room_width + 1)
ax.set_ylim(-1, room_depth + 1)
ax.set_aspect('equal')
ax.set_title("éƒ¨å±‹ã®å¹³é¢å›³ï¼ˆä¸Šã‹ã‚‰è¦‹ãŸå›³ï¼‰", fontproperties=font_prop, fontsize=12)
ax.legend(loc='center left', bbox_to_anchor=(1.02, 0.5), prop=font_prop)
st.pyplot(fig)

# --- éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ ---
st.sidebar.header("éŸ³æºãƒ•ã‚¡ã‚¤ãƒ«")
audio_file = st.sidebar.file_uploader("WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['wav'])
if audio_file is not None:
    fs, audio = wavfile.read(audio_file)
    if audio.ndim > 1:
        audio = np.mean(audio, axis=1)
    audio = audio.astype(np.float32) / np.max(np.abs(audio))
elif os.path.exists("source.wav"):
    fs, audio = wavfile.read("source.wav")
    if audio.ndim > 1:
        audio = np.mean(audio, axis=1)
    audio = audio.astype(np.float32) / np.max(np.abs(audio))
    st.sidebar.info("source.wav ã‚’ä½¿ç”¨ä¸­")
else:
    st.sidebar.error("éŸ³æºãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    st.stop()

# --- ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ ---
if st.button("â–¶ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"):
    # ææ–™å®šç¾©
    material_dict = {
        row['material']: pra.Material({
            'coeffs': [row[f'{f}Hz'] for f in [125, 250, 500, 1000, 2000, 4000]],
            'center_freqs': [125, 250, 500, 1000, 2000, 4000]
        }) for _, row in materials_df.iterrows()
    }

    # éƒ¨å±‹ã®ä½œæˆ
    room = pra.ShoeBox(
        room_dim,
        fs=fs,
        materials={face: material_dict[walls[face]] for face in walls},
        max_order=17
    )

    room.add_source([src_x, src_y, src_z], signal=audio)
    room.add_microphone_array(pra.MicrophoneArray([[mic_x], [mic_y], [mic_z]], fs))
    room.compute_rir()
    room.simulate()

    # å†ç”Ÿã¨å¯è¦–åŒ–
    st.subheader("ğŸ”‰ å…ƒéŸ³æº")
    st.audio(audio, sample_rate=fs)

    st.subheader("ğŸ§ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³éŸ³æº")
    signal = room.mic_array.signals[0]
    signal = signal / np.max(np.abs(signal))
    st.audio(signal, sample_rate=fs)
    # wavfile.write("mic0.wav", fs, (signal * 32767).astype(np.int16))
    # st.success("mic0.wav ã‚’ä¿å­˜ã—ã¾ã—ãŸ")

    st.subheader("ğŸ“ˆ ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”æ³¢å½¢")
    rir = room.rir[0][0]
    fig, ax = plt.subplots()
    ax.plot(np.arange(len(rir)) / fs, rir)
    ax.set_xlabel("Time [s]",fontproperties=font_prop)
    ax.set_ylabel("Amplitude",fontproperties=font_prop)
    ax.set_title("ã‚¤ãƒ³ãƒ‘ãƒ«ã‚¹å¿œç­”",fontproperties=font_prop)
    st.pyplot(fig)
    st.audio(rir / np.max(np.abs(rir)), sample_rate=fs)

    # æ®‹éŸ¿æ™‚é–“ï¼ˆT30ï¼‰
    st.subheader("â± æ®‹éŸ¿æ™‚é–“è§£æ (1/1 Oct)")
    cfreqs = [63, 125, 250, 500, 1000, 2000, 4000, 8000]
    T30_values = []
    for fc in cfreqs:
        y = octave_band_filter(rir, fs, fc)
        T30 = reverb_time_T30(y, fs)
        T30_values.append(T30)

    df = pd.DataFrame({'ä¸­å¿ƒå‘¨æ³¢æ•° (Hz)': cfreqs, 'T30 (s)': T30_values})
    st.dataframe(df, hide_index=True)
